{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP-8:  Membership Attack - annotated solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhairyachandra/Module-2-Deep-Learning-ICP/blob/master/ICP_8_Membership_Attack_annotated_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "78eef720-26df-4d3d-a98f-af1adb52b338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = 'content/drive/My Drive/Colab Notebooks/Cybersecurity/NN Attacks/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "9a722076-bcbd-4422-ba5f-d7686d40fe62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root=project_path+'/data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/170498071 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to content/drive/My Drive/Colab Notebooks/Cybersecurity/NN Attacks//data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:02, 69606790.24it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting content/drive/My Drive/Colab Notebooks/Cybersecurity/NN Attacks//data/cifar-10-python.tar.gz to content/drive/My Drive/Colab Notebooks/Cybersecurity/NN Attacks//data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "987fd2ce-6b62-4d71-d677-af2d6e6c021e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  dog  bird horse  ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+wT/A3ggNZlwRuG4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "503e306d-d0c4-4e3a-b7e2-b5da5014acce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx = indices[split3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx)\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx)\n",
        "\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx)\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx)\n",
        "\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) output of fc is 10 cuz we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # input channels = 3, output channels=6, kernel_size =5 \n",
        "        self.pool = nn.MaxPool2d(2, 2)  # kernel size = 2, stride = 2\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "        \n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "58d7012f-3c00-4e82-81d5-a264e446ddbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(target_model.parameters(), lr=0.01)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(target_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = target_model(inputs) # make a prediction: forward prop\n",
        "        \n",
        "        loss = criterion(outputs, labels) # calculate the loss\n",
        "        \n",
        "        loss.backward() # calculate gradients\n",
        "        \n",
        "        optimizer.step() # updaate weights in backprop\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "       \n",
        "        \n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training the Target model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training the Target model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "08b57593-5a7e-43fd-9763-831087cc5b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in target_out_loader:\n",
        "        images, labels = data\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 12 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "151cd521-971d-424f-de61-2c1809183412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP trail use the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = Net()\n",
        "shadow_criterion = nn.CrossEntropyLoss()\n",
        "shadow_optimizer = optim.SGD(shadow_model.parameters(), lr=0.0001)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    shadow_running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(shadow_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = shadow_model(inputs) # make a prediction: forward prop\n",
        "        \n",
        "        shadow_loss = shadow_criterion(outputs, labels) # calculate the loss\n",
        "        \n",
        "        shadow_loss.backward() # calculate gradients\n",
        "        \n",
        "        shadow_optimizer.step() # updaate weights in backprop\n",
        "\n",
        "        # print statistics\n",
        "        shadow_running_loss += shadow_loss.item()\n",
        "       \n",
        "    print(shadow_running_loss / len(shadow_train_loader))\n",
        "    shadow_running_loss = 0.0\n",
        "\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.300771483353206\n",
            "2.2877343199690996\n",
            "2.217390334119602\n",
            "2.1361659187443403\n",
            "2.1112036571210746\n",
            "2.057891899225663\n",
            "2.000344443077944\n",
            "1.9450959478105818\n",
            "1.88696850380119\n",
            "1.8228241618798704\n",
            "1.764731126172202\n",
            "1.7466736131784868\n",
            "1.7235473187602297\n",
            "1.6769684212548392\n",
            "1.650014378586594\n",
            "1.6615508210902312\n",
            "1.6320169902577693\n",
            "1.6032057368025487\n",
            "1.599801066578651\n",
            "1.5904182244320304\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "8ac62f6b-a234-4596-bba1-3c958eeee447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "shadow_model = shadow_model.cuda()\n",
        "# freeze the Shadow model \n",
        "for param in shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[110])\n",
        "\n",
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 1] and zip them together\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([2.8996774e+02, 7.8781679e-02, 5.4201694e+00, 3.4879431e-01,\n",
            "       1.6254312e+00, 9.0044960e-02, 2.5706062e-01, 1.2541345e-01,\n",
            "       6.7440002e+01, 1.5683171e-01], dtype=float32), 1]\n",
            "[array([ 7.1480474 ,  1.7664242 ,  1.146807  ,  0.34205613,  1.1135657 ,\n",
            "        0.20977712,  0.23564306,  0.23445417, 16.342299  ,  2.086763  ],\n",
            "      dtype=float32), 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "outputId": "803a7f4d-eeef-41b7-f1a3-ecb6c0e59701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# create the Attack Model\n",
        "# A NN binary classifier {0, 1}\n",
        "# the input is a propability distribution and the output is 0 (out) or 1 (in in the training data)\n",
        "\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in target_train_loader:\n",
        "       \n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "print('Finished Training the Attack model')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-6816a7672f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mattack_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [6144 x 32], m2: [10 x 20] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:290"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "outputId": "a737318b-8289-4a82-b932-88fdc605cfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "\n",
        "\n",
        "\n",
        "# and then input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluare the attack model\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4cc2cbbc8cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mload_target_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/target_checkpoint.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mload_target_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_target_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# freeze the Shadow model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_checkpoint' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}